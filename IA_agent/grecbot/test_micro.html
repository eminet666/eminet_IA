<!DOCTYPE html>
<html lang="fr">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test Micro iOS / Chrome</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, sans-serif;
            background: #f5f5f5;
            padding: 20px;
            text-align: center;
        }

        button {
            padding: 12px 20px;
            font-size: 16px;
            margin: 10px;
        }

        #status {
            margin-top: 15px;
            font-weight: bold;
        }

        #visualizer {
            margin-top: 20px;
            width: 100%;
            height: 100px;
            background: #ddd;
            position: relative;
            overflow: hidden;
        }

        #bar {
            height: 100%;
            width: 0;
            background: #4caf50;
        }
    </style>
</head>

<body>

    <h1>üé§ Test du micro</h1>
    <p>Appuie sur le bouton pour tester le micro</p>

    <button id="startBtn">D√©marrer</button>
    <button id="stopBtn" disabled>Arr√™ter</button>

    <p id="status">Statut : en attente</p>

    <div id="visualizer">
        <div id="bar"></div>
    </div>

    <script>
        let audioCtx;
        let analyser;
        let dataArray;
        let source;
        let stream;
        let animationId;

        const startBtn = document.getElementById("startBtn");
        const stopBtn = document.getElementById("stopBtn");
        const status = document.getElementById("status");
        const bar = document.getElementById("bar");

        startBtn.addEventListener("click", async () => {
            status.textContent = "Demande d‚Äôacc√®s au micro‚Ä¶";
            try {
                stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                source = audioCtx.createMediaStreamSource(stream);
                analyser = audioCtx.createAnalyser();
                analyser.fftSize = 256;
                dataArray = new Uint8Array(analyser.frequencyBinCount);
                source.connect(analyser);

                status.textContent = "üéôÔ∏è Micro actif ! Parle dans le micro‚Ä¶";

                startBtn.disabled = true;
                stopBtn.disabled = false;

                function visualize() {
                    analyser.getByteTimeDomainData(dataArray);
                    // calcul d‚Äôun niveau moyen
                    let sum = 0;
                    for (let i = 0; i < dataArray.length; i++) {
                        let val = dataArray[i] - 128;
                        sum += val * val;
                    }
                    let rms = Math.sqrt(sum / dataArray.length);
                    let percent = Math.min(rms * 2, 100); // 0-100%
                    bar.style.width = percent + "%";
                    animationId = requestAnimationFrame(visualize);
                }
                visualize();

            } catch (err) {
                console.error(err);
                status.textContent = "‚ùå Erreur micro : " + err.name + " ‚Äì " + err.message;
            }
        });

        stopBtn.addEventListener("click", () => {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            if (animationId) cancelAnimationFrame(animationId);
            bar.style.width = "0";
            status.textContent = "‚èπÔ∏è Micro arr√™t√©";
            startBtn.disabled = false;
            stopBtn.disabled = true;
        });
    </script>

</body>

</html>